{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "997079f2",
   "metadata": {},
   "source": [
    "## 딥러닝 vs 기계학습 vs 인공지능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e91c47",
   "metadata": {},
   "source": [
    "### 인공지능\n",
    "- 기계가 **사람의 행동을 모방**하게 하는 기술\n",
    "\n",
    "### 기계학습\n",
    "- 기계가 일일이 코드로 명시하지 않은 동작을 **데이터로부터 학습**하여 실행할 수 있도록 하는 알고리즘을 개발하는 연구 분야\n",
    "\n",
    "###  딥러닝\n",
    "- 기계 학습의 한 분야인 인공 신경망에 기반하여, **많은 양의 데이터를 학습**해 뛰어난 성능을 이끌어내는 연구 분야"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7fef26",
   "metadata": {},
   "source": [
    "## 딥러닝 vs 빅데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e989c9",
   "metadata": {},
   "source": [
    "### 빅데이터\n",
    "- 데이터베이스 관리\n",
    "- 데이터 저장/유통\n",
    "- 데이터 수집\n",
    "- 데이터 신뢰성 확보\n",
    "- 데이터 시각화\n",
    "- 데이터 통계 분석\n",
    "- 데이터 마이닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccb450a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T06:19:36.013477Z",
     "start_time": "2021-12-17T06:19:35.988963Z"
    }
   },
   "source": [
    "## 딥러닝은 왜 특별한가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7377cad6",
   "metadata": {},
   "source": [
    "- 기계학습(Machine Learning)은 특징을 찾고 찾은 특징을 벡터로 표현을 하여 벡터를 통해 학습한다.\n",
    "- 딥러닝(Deep Learning)은 특징조차도 직접 찾는다. 완전히 맡기지 않을 때도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e637232b",
   "metadata": {},
   "source": [
    "## 딥러닝으로 할 수 있는 것은"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998e65f3",
   "metadata": {},
   "source": [
    "- 분류(classification)\n",
    "- 회귀(regression)\n",
    "- 물체 검출(Object Detection)\n",
    "- 영상 분할(Image Segmentation)\n",
    "- 영상 초해상도(Image Super Resolution)\n",
    "- 예술적 창조물(Artistic Creation with GAN)\n",
    "- 강화 학습(Reinforcement Learning) ex)Alphago"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee7902b",
   "metadata": {},
   "source": [
    "## 딥러닝의 구성요소란"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6404e0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T06:31:24.115969Z",
     "start_time": "2021-12-17T06:31:24.089964Z"
    }
   },
   "source": [
    "### 학습 단계(Training Phase)\n",
    "- 학습 데이터셋(Training Dataset) -> 학습 입력(Training Input) -> 네트워크 구조(Network Architecture) -> 손실 함수(Loss Function): 학습 정답(Training Groundtruth)과 비교 -> 알고리즘 최적화 기법(Algorithm Optimizer)\n",
    "\n",
    "### 테스트 단계(Test Phase)\n",
    "- 테스트 입력(Test Input) -> 학습된 네트워크(Trained Network) -> 평가 지표(Evaluation Metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5a735a",
   "metadata": {},
   "source": [
    "## 딥러닝의 시조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af94cab8",
   "metadata": {},
   "source": [
    "- 최초의 인공신경망 개념(McCulloh and Pitts, 1943)\n",
    "- Rosenblatt의 퍼셉트론 구조(Rosenblatt, 1958)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684fed21",
   "metadata": {},
   "source": [
    "## 퍼셉트론의 동작"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5f536c",
   "metadata": {},
   "source": [
    "- 퍼셉트론 하나가 할 수 있는 것은 직선을 만드는 것\n",
    "- 직선을 통해 데이터를 표현할 수도 분리할 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f55cf94",
   "metadata": {},
   "source": [
    "## XOR와 AI Winter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad4fb8f",
   "metadata": {},
   "source": [
    "- 직선하나가 OR, AND는 해결가능하나 XOR은 직선 하나로 해결되지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892610ee",
   "metadata": {},
   "source": [
    "## 다층 퍼셉트론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0830fa24",
   "metadata": {},
   "source": [
    "- 다층 퍼셉트론(Multi-Layered Perceptrons; MLP, 1986)\n",
    "- 첫번째 계층(입력 계층) -> 두번째 계층(은닉 계층) -> 세번째 계층(출력 계층)\n",
    "- MLP로 XOR 문제를 해결한 예"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaaecc4",
   "metadata": {},
   "source": [
    "## 역전파의 등장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3eabe1",
   "metadata": {},
   "source": [
    "- 오류 역전파 알고리즘(Backpropagation Algorithm; BP)\n",
    "- 정방향(Feed forward) -> error -> 역방향(Backward)\n",
    "- MLP와 BP 알고리즘으로 해결한 필기숫자 인식(MNIST) 문제 (LeCun, 1989)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f83e45",
   "metadata": {},
   "source": [
    "## 두번째 AI Winter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1fb3d1",
   "metadata": {},
   "source": [
    "- 계층이 깊어질수록 학습이 어려운 기울기 소실(Vanishing Gradient) 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9386f409",
   "metadata": {},
   "source": [
    "## 이미지넷 경연대회\n",
    "- Fei-Fei Li 교수의 대규모 영상 분류 데이터셋 ImageNet과 경연대회 ILSVRC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d80ece7",
   "metadata": {},
   "source": [
    "## 알렉스넷과 딥러닝의 비상\n",
    "- 2012 ILSVRC (ImageNet Large Scale Visual Recognition Competition) 우승과 함께 시작된 딥러닝의 급부상\n",
    "- GPU를 병렬로 사용\n",
    "- AlexNet(Krizhevsky et al.,2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cd50cc",
   "metadata": {},
   "source": [
    "## Framework의 등장\n",
    "- Caffe2, MatConvNet\n",
    "- 학계에 대중적으로 알려진 첫 프레임워크 Caffe. MATLAB 환경에 익숙한 연구원들을 위한 MatConvNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4025311b",
   "metadata": {},
   "source": [
    "## 현재의 2강"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ab7d45",
   "metadata": {},
   "source": [
    "- 현재는 Tensorflow와 PyTorch의 양강 구도가 이루어지고 있다.\n",
    "- 진입 장벽이 낮고 속도가 빠른 PyTorch와, 다양한 플랫폼으로 확장되고 있는 Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d421d9",
   "metadata": {},
   "source": [
    "## Cloud 플랫폼의 대중화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313b5a4a",
   "metadata": {},
   "source": [
    "- aws, Google Cloud Platform, Microsoft Azure\n",
    "- 초기에 클라우드 시장을 점령한 AWS, 최근 공격적인 마케팅을 선보이고 있는 GCP, B2B 중심으로 클라우드 시장에 자리매김한 Azure의 3강 구도라고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1bf8bb",
   "metadata": {},
   "source": [
    "## 하드웨어의 대중화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd0df5d",
   "metadata": {},
   "source": [
    "- GTX, Titan, TESLA로 구분되는 NVIDIA 사이 GPU 라인업\n",
    "- GTX 시리즈는 게이밍 용이지만, 딥러닝 연구에서 최고의 가성비를 내면서 딥러닝 연구의 대중화를 이끌었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7178679e",
   "metadata": {},
   "source": [
    "## 뉴런의 그래프 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef14f74",
   "metadata": {},
   "source": [
    "- 보통 신경망을 표현할 때, **Graph의 Node와 Edge를 이용해 표현**한다.\n",
    "- 여기서 **Node는 단일 뉴런 연산**을, **Edge는 뉴런의 연결성**을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd65741",
   "metadata": {},
   "source": [
    "## Fully-connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf75504",
   "metadata": {},
   "source": [
    "- 뉴런이 모인 한 단위를 계층(Layer)라고 하며, 이전 계층과 **모든 뉴런이 서로 연결된 계층**을 **Fully-Connected Layer(Dense Layer)**라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e34d76",
   "metadata": {},
   "source": [
    "## 얇은 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66daa3a",
   "metadata": {},
   "source": [
    "- 입력, 은닉, 출력의 3가지 계층으로 되어 있으며, 은닉 계층과 출력 계층이 Fully Connected 계층인 모델을 **얕은 신경망(Shallow Neural Network)**라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995b984d",
   "metadata": {},
   "source": [
    "## 얇은 신경망으로 할 수 있는 것은"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ac1ab6",
   "metadata": {},
   "source": [
    "- 회귀\n",
    "    - 키, 몸무게, 나이 등을 통한 기대 수명 예측\n",
    "    - 지역, 집 면적, 건축 년도 등을 통한 적정 매매가 예측\n",
    "\n",
    "- 분류\n",
    "    - 면접 점수, 실기 점수, 필기 점수 등을 통한 합격 당락 여부 예측\n",
    "    - 꽃잎의 너비, 꽃잎의 색깔 등을 통해 어떤 꽃인지 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f036a628",
   "metadata": {},
   "source": [
    "## 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc26dc2",
   "metadata": {},
   "source": [
    "- 데이터를 표현하는 대표적인 선 또는 모델을 찾는 것 \n",
    "- 잡음이 있는 학습 샘플로부터 규칙을 찾아 **연속된 값의 출력을 추정하는 것을 회귀**라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e643b",
   "metadata": {},
   "source": [
    "## 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d56445",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T07:18:23.628450Z",
     "start_time": "2021-12-17T07:18:23.613703Z"
    }
   },
   "source": [
    "- 분류는 데이터를 구분하는 경계선을 찾는 것\n",
    "- 입력 값을 분석해 **특정 범주(Category)로 구분하는 작업**을 분류(Classification)라고 한다.\n",
    "- 범주가 2개일 경우 '이진 분류(Binary classification)', 그 이상은 '다중 분류(Multi-class classification)'라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc69d3b6",
   "metadata": {},
   "source": [
    "## 얇은 신경망을 이용한 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63590e61",
   "metadata": {},
   "source": [
    "- 회귀 문제도 출력층이 여러개가 가능하다\n",
    "- 얕은 신경망의 동작은 **출력 계층의 활성 함수**에 의해 달라진다.\n",
    "- 회귀는 전 범위의 연속된 값을 출력하므로, 보통 Identity function(항등 함수)을 사용한다.\n",
    "- 출력 계층이 출력 단위 회귀문제를 풀어야하는 것이라면 그 모델의 출력층의 activation function은 설정하지 않는다. 자동으로 y=x 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996bfbe1",
   "metadata": {},
   "source": [
    "## 얇은 신경망을 이용한 이진 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cbc6df",
   "metadata": {},
   "source": [
    "- 이진분류는 출력층이 하나면 된다. Softmax를 써서 출력을 2개로 뽑아 다중분류처럼 쓸 수도 있다\n",
    "- 이진 분류를 위한 출력은 **0~1 사이의 실수 값**이며, 활성함수로 Sigmoid function을 사용한다\n",
    "- threshold 0.5보다 작으면 첫번째 Class, 0.5보다 크면 두번째 Class로 분류한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfbe587",
   "metadata": {},
   "source": [
    "## 다중 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680da8bb",
   "metadata": {},
   "source": [
    "- SoftMax 활성 함수를 이용해 다중 분류 문제를 해결할 수 있다.\n",
    "- 각 출력은 **해당 Class에 속할 확률**을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3408f05f",
   "metadata": {},
   "source": [
    "## 뉴런의 수학적 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7035f3c",
   "metadata": {},
   "source": [
    "- 뉴런은 수학적으로 **두 벡터의 내적**으로 쉽게 표현할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ed98bb",
   "metadata": {},
   "source": [
    "## Fully-connected layer의 수학적 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b64806c",
   "metadata": {},
   "source": [
    "- FC 계층은 여러 개의 뉴런을 한 곳에 모아둔 것으로, **Matrix 곱셈 연산**으로 표현된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a747af",
   "metadata": {},
   "source": [
    "## Input Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e151fb1",
   "metadata": {},
   "source": [
    "- 입력 계층(Input Layer)\n",
    "    - 입력 계층은 **아무런 연산도 일어나지 않는다.**\n",
    "    - 신경망의 입력을 받아서 다음 계층으로 넘기는 역할\n",
    "    - **무엇을 입력으로 주어야 하는가? -> 특징 추출 문제**\n",
    "    - 계층의 크기 = Node의 개수 = 입력 Scalar의 수 = 입력 Vector의 길이\n",
    "    - $ x = [x_0, x_1, x_2,...,x_{N-1}]^T $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2542b79",
   "metadata": {},
   "source": [
    "## Hidden Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bfe7e1",
   "metadata": {},
   "source": [
    "- 은닉 계층(Hidden Layer)\n",
    "    - 은닉 계층은 입력 계층과 연결된 **전결합 계층**이다.\n",
    "    - 입출력 관점에서 볼 때 드러나지 않는다고 하여, 은닉 계층이라 한다.\n",
    "    - 복잡한 문제를 해결할 수 있게 하는 핵심적인 계층.\n",
    "    - 얕은 신경망에서는 1개의 은닉 계층만을 사용한다.\n",
    "    - $ h = a_h(W_hx + b_h) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2c7ac4",
   "metadata": {},
   "source": [
    "## Output Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2f8627",
   "metadata": {},
   "source": [
    "- 출력 계층(Output Layer)\n",
    "    - 출력 계층은 은닉 계층 다음에 오는 전결합 계층이다.\n",
    "    - 신경망의 외부로 출력 신호를 전달하는 데에 사용된다.\n",
    "    - 신경망의 **기능은 출력 계층의 활성 함수에 의해 결정**된다.\n",
    "    - 출력 계층의 크기 = 출력의 Scalar 수 = 출력 벡터의 길이\n",
    "    - $ y = a_O(W_Oh + b_O) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde882ec",
   "metadata": {},
   "source": [
    "## 선형 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e251e671",
   "metadata": {},
   "source": [
    "- 선형 회귀(Linear Regression): 데이터를 가장 잘 표현하는 선형식을 찾는 동작\n",
    "    - $ y = wx + b $\n",
    "    - $ w^* = arg \\min_w \\frac{1}{N} \\sum_i \\frac{(y-y_i)^2}{2} $\n",
    "    - 평균제곱에러(Mean Squared Error; MSE): $ \\frac{1}{N} \\sum_i \\frac{(y-y_i)^2}{2} $\n",
    "    - **'MSE를 최소로 하는 w를 찾아라.'**\n",
    "    - 단순 선형 회귀의 예. 독립 변수(입력)이 하나이므로, 추정해야 할 변수도 하나. 단, 편향을 포함하면 2개가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac696924",
   "metadata": {},
   "source": [
    "## Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a608032d",
   "metadata": {},
   "source": [
    "- 참값: $ y = [10.5, 3.6] $\n",
    "- 예측값: $ \\tilde y = [8.3, 4.6] ------> E = (10.5 - 8.3)^2 + (3.6-4.6)^2 = 5.8 $\n",
    "- 예측값: $ \\tilde y = [9.4, 3.8] ------> E = (10.5 - 9.4)^2 + (3.6-3.8)^2 = 1.2 $\n",
    "- MSE를 이용해, 고양이의 길이와 체중의 오차를 종합적으로 판단할 수 있다. 낮을수록 좋은 것이 아닌 상대적인 비교를 통한 더 낮은 오차를 채택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76266199",
   "metadata": {},
   "source": [
    "## 다중 선형 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec3f6f8",
   "metadata": {},
   "source": [
    "- $ y = wx + b ---> y = w_0x_0 + w_1x_1 + w_2x_2 + ... + w_{N-1}x_{N-1} + b ---> \\sum_{i=0}^{N-1}{w_ix_i} + b ---> w^Tx + b $ \n",
    "- 단일 입력이 아닌, 다중 입력을 받을 경우에는 변수가 확장되어 **벡터의 내적**이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34178789",
   "metadata": {},
   "source": [
    "## 다중 선형 회귀의 상상"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4c4dd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T09:00:31.890253Z",
     "start_time": "2021-12-17T09:00:31.873253Z"
    }
   },
   "source": [
    "- $ y = wx + b ---> y = w_0x_0 + w_1x_1 + b ---> w^Tx + b $\n",
    "- 변수가 하나 추가될 때 마다 차원이 하나씩 추가된다.\n",
    "- 직선 -> 평면 -> 초평면"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0a63ba",
   "metadata": {},
   "source": [
    "## 신경망의 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096e2f0f",
   "metadata": {},
   "source": [
    "- 얕은 신경망으로 회귀를 수행할 경우, **출력 계층은 선형 회귀와 동일**하다.\n",
    "- 입력 계층에서 **은닉 계층으로 추가적인 변환**이 있다는 것이 다른 점! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b10ed",
   "metadata": {},
   "source": [
    "## 은닉층의 효과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11891b20",
   "metadata": {},
   "source": [
    "- 선형적으로 분포되지 않는 입력 -> 선형적으로 분포하는 **은닉 계층(특징)** -> 선형 회귀\n",
    "- 입력 Space를 기준으로 보면 **회귀 곡선**이 된다!\n",
    "- 은닉층이 하나 이상 추가가되면 직선이 아니라 복잡한 경계면을 만들 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5c7b05",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27c5248",
   "metadata": {},
   "source": [
    "- 로지스틱 회귀(Logistic Regression): 범주형 데이터를 대상으로 하는 회귀. 분류기법으로도 볼 수 있다.\n",
    "- $ w^* = arg \\min_w ${$ -\\sum_i ylog\\tilde y + (1-y)log(1-\\tilde y) $}\n",
    "- **'이진 교차 엔트로피를 최소화한다'**\n",
    "- 로지스틱 회귀는 선형 회귀와 비슷하나, **범주형 데이터를 분류하는 방향으로 선을 긋는다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57898be3",
   "metadata": {},
   "source": [
    "## Sigmoid Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed40afc",
   "metadata": {},
   "source": [
    "- $ sigmoid(x) = \\frac{1}{1+e^-x} $ \n",
    "- 값이 작아질수록 0, 커질수록 1에 수렴\n",
    "- 모든 실수 입력 값에 대해 출력이 정의됨\n",
    "- 출력이 0~1 사이로, '확률'을 표현할 수 있음\n",
    "- 입력 값이 0에 가까울 수록 출력이 빠르게 변함\n",
    "- 모든 점에서 미분 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09089c49",
   "metadata": {},
   "source": [
    "## Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ca9be6",
   "metadata": {},
   "source": [
    "- 교차 엔트로피 오차(Cross entropy error;CEE)\n",
    "- $ E = -\\sum_i ylog\\tilde y + (1-y)log(1-\\tilde y) $\n",
    "- $ y $ : 학습데이터 정답 (0 or 1)\n",
    "- $ \\tilde y $ : 학습데이터 입력으로 추정한 출력 (0~1) \n",
    "- 정확히 맞추면 오차가 0, **틀릴수록 오차가 무한히 증가**하는 특징이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d52b5dc",
   "metadata": {},
   "source": [
    "## 다중 로지스틱 회귀의 기하학적 특징"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbc7895",
   "metadata": {},
   "source": [
    "- 변수가 하나 추가될 때 마다 차원이 하나씩 추가된다. 직선 -> 평면 -> 초평면"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737dbb32",
   "metadata": {},
   "source": [
    "## 얇은 신경망과 이진 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7675b8",
   "metadata": {},
   "source": [
    "- 얕은 신경망으로 Classification을 수행할 경우, **출력 계층은 로지스틱 회귀와 동일**하다.\n",
    "- 입력 계층에서 **은닉 계층으로 추가적인 변환**이 있다는 것이 다른 점!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9af3548",
   "metadata": {},
   "source": [
    "## 은닉계층과 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acd7b44",
   "metadata": {},
   "source": [
    "- 선형적으로 분리되지 않는 Class -> 선형적으로 분리되는 **은닉 계층(특징)** -> 로지스틱 회귀\n",
    "- 입력 Space를 기준으로 보면 **Decision Boundary가 곡선**이 된다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b452368",
   "metadata": {},
   "source": [
    "## 다중 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235cd56b",
   "metadata": {},
   "source": [
    "- 이진 분류에서는 '어떤 물체'인지 표현할 필요가 없으나, **다중 분류에서는 '어떤 물체'인지 표현**해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7495dd2e",
   "metadata": {},
   "source": [
    "## 원 핫 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52532a05",
   "metadata": {},
   "source": [
    "- One-Hot Encoding: 한 개의 값만 1이고, 나머지 값은 0인 벡터로 표현하는 기법\n",
    "- 원 핫 인코딩된 벡터는 미리 정해둔 Table을 이용해 어떤 물체인지 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee41980e",
   "metadata": {},
   "source": [
    "## 희소 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58da970",
   "metadata": {},
   "source": [
    "- 희소 벡터(Sparse Vector): 대부분의 값이 0이고 크기가 있는 값이 희소하게 나타나는 벡터\n",
    "- 희소 표현을 이용해 벡터 전체를 표기하지 않고, 숫자 하나로 표현할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce48d514",
   "metadata": {},
   "source": [
    "## 다중 클래스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8a4723",
   "metadata": {},
   "source": [
    "- **한가지 확률만 100%이고 나머지는 0%인 것이 정답** (=원-핫 인코딩)\n",
    "- 실제 알고리즘 출력을 확률로 변환하기 위해 Softmax함수를 사용한다.\n",
    "- Softmax의 모든 출력단의 합은 1, 가장 높은 출력값을 가진 것을 정답으로 본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1069cb68",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3dff48",
   "metadata": {},
   "source": [
    "- $ softmax(x)_i = \\frac {e^{x_i}}{\\sum_j e^{x_j}} $\n",
    "- 각 입력의 지수함수를 정규화한 것\n",
    "- 각 출력은 0~1 사이의 값을 가짐\n",
    "- 모든 출력의 합이 반드시 1이 됨\n",
    "- 여러 경우의 수 중 한가지에 속할 '확률'을 표현\n",
    "- Softmax는 최종 출력 단에서 **N가지 범주로 분류하는 Multi-class classification**에 쓰임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed4e91",
   "metadata": {},
   "source": [
    "## Softmax와 Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1446a82e",
   "metadata": {},
   "source": [
    "- $ softmax([x, 0])_0 = \\frac {e^x}{e^x + e^0} = \\frac {1}{1 + e^-x} = sigmoid(x) $\n",
    "- Sigmoid는 하나의 입력을 0으로 강제한 2-Class Softmax 함수와 동일하다.\n",
    "- 2가지 클래스를 구분하기 위해 1개의 입력을 받는다는 점에 주목."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d880179",
   "metadata": {},
   "source": [
    "## 정답과 출력의 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aa6b55",
   "metadata": {},
   "source": [
    "- 교차 엔트로피 오차(Cross entropy error;CEE)\n",
    "- $ E = -\\sum_i y_ilog\\tilde y_i $\n",
    "- $ y_i $ : 학습데이터 정답의 i번째 요소 (원-핫 인코딩)\n",
    "- $ \\tilde y_i $ : 학습데이터 입력으로 추정한 출력의 i번째 요소\n",
    "- 원-핫 인코딩으로 인해, **정답인 클래스에 대해서만 오차를 계산.**\n",
    "- 정확히 맞추면 오차가 0, 틀릴수록 오차가 무한히 증가하는 특징이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd26110",
   "metadata": {},
   "source": [
    "## Cross Entropy Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e5d31a",
   "metadata": {},
   "source": [
    "- $ softmax(x)_i = \\frac {e^{x_i}}{\\sum_j e^{x_j}} $\n",
    "- $ \\tilde y $ = [0.0, 0.0, **0.6**, 0.3, 0.1] -> E = 0.51\n",
    "- $ \\tilde y $ = [0.0, 0.0, **0.8**, 0.15, 0.05] -> E = 0.22\n",
    "- 오차를 내는 과정에서는 정답 클래스만 비교하지만, 다중 클래스 분류의 활성함수인 Softmax로 인해 다른 클래스에 대한 학습에도 영향을 준다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f186aadc",
   "metadata": {},
   "source": [
    "## LeNET-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d343561",
   "metadata": {},
   "source": [
    "- 얀 르쿤이 1998년 우편물에 필기체 인식을 위해 개발\n",
    "- LeNET은 현대적인 개념의 딥러닝이 확립되기 전에 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2f2fba",
   "metadata": {},
   "source": [
    "## ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d951f277",
   "metadata": {},
   "source": [
    "- 이미지넷은 1400만개의 이미지 데이터와 1000개의 클래스의 데이터\n",
    "- 2010년부터 대회 개최\n",
    "- CNN 계열의 최초 우승이 2012년 알렉스 넷"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a87a550",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254d9069",
   "metadata": {},
   "source": [
    "- 힌튼 교수 연구팀에서 창안\n",
    "- 2개의 GPU에서 실행(GTX580)\n",
    "- 두 개의 conv넷을 구성하고 하나씩 GPU를 할당하고 중간에 정보 교환\n",
    "- 이미지넷 데이터를 5~6일 정도 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1c5829",
   "metadata": {},
   "source": [
    "## ZFNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c20e0be",
   "metadata": {},
   "source": [
    "- 2013 ILSVRC 우승\n",
    "- 알렉스넷의 문제점을 시각화를 통해 확인 후 해당부분을 개선\n",
    "- GTX580으로 12일 학습\n",
    "- 의의는 모델 튜닝만으로도 좋은 결과를 얻을 수 있다는 사례를 남김"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9899b1d0",
   "metadata": {},
   "source": [
    "## VGGNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4105af31",
   "metadata": {},
   "source": [
    "- 2014 ILSVRC 준우승\n",
    "- 깊은 신경망. 3x3 컨블루션 필터만을 사용. 매우 단순한 구조\n",
    "- 작은 필터로 깊은 네트워크를 형성하는 것이 유리함을 보여줌\n",
    "- VGG는 이미지의 특징을 추출할 때 많이 사용\n",
    "- 일부 계층의 특징으로 스타일을 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54780170",
   "metadata": {},
   "source": [
    "## GoogLeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d171918",
   "metadata": {},
   "source": [
    "- 2014 ILSVRC 우승\n",
    "- 이후 InceptionV4로 발전했기 때문에 GoogLeNet을 인셉션v1이라고도 함\n",
    "- 기존의 방식과 달리 네트워크 속에 네트워크를 두는 방식으로 구성\n",
    "- 왼쪽에서 빨간색 박스가 인셉션 모듈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d24506",
   "metadata": {},
   "source": [
    "## GoogLeNet - 인셉션 모듈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff25f86",
   "metadata": {},
   "source": [
    "- 1x1, 3x3, 5x5, 맥스풀링으로 구성\n",
    "- 1x1은 채널의 특성을 인식\n",
    "- 3x3과 5x5는 서로 다른 크기의 영역에서 공간의 특징과 채널의 특징을 인식\n",
    "- 맥스 풀링은 가장 두드러진 특징을 인식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bcad8d",
   "metadata": {},
   "source": [
    "## GoogLeNet - 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5ce1c2",
   "metadata": {},
   "source": [
    "- 스템 : 도입부에는 일반적인 구조로 진행 (Conv - Pool - Conv - Pool)\n",
    "- 몸체 : 인셉션 모듈 9개\n",
    "- 최종 분류기 : FC 대선 mean pooling을 통해 파라미터 수를 줄임\n",
    "- 보조 분류기 : 하위 계층에 그레디언트를 원활히 전달 (훈련때만 사용)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3e2711",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286b6900",
   "metadata": {},
   "source": [
    "- 최초로 사람의 인지능력(5%대)보다 좋은 성능\n",
    "- 152계층의 엄청난 깊이를 가짐\n",
    "- Residual connection의 구조를 가짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf9a115",
   "metadata": {},
   "source": [
    "## ResNet - Bottleneck"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dad6a3",
   "metadata": {},
   "source": [
    "- 3x3 Conv 앞뒤에 1x1 Conv를 배치\n",
    "- 1x1 Conv로 채널을 줄였다가 다시 확대"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
